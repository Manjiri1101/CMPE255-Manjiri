{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3_ANN_Manjiri.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPv3RLJhzhJLPH/F2LxcuBR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manjiri1101/CMPE255-Manjiri/blob/main/Assignment3/Assignment3_ANN_Manjiri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_P3MvtdT9CQ"
      },
      "source": [
        "# **Assignment 3**\n",
        "## CMPE 255 - Data Mining\n",
        "## Use state of art libraries for Approximate nearest neighbor search for your favorite data set\n",
        "## Name:  Manjiri Kadam\n",
        "### Student ID: 015312076\n",
        "\n",
        "### **Objective** ✈\n",
        "Using any data set you want, implement colabs for the following ANN algorithms \n",
        "Write proper documentation in read.me file and colabs \n",
        "\n",
        " \n",
        "1.  LSH\n",
        "\n",
        "2.  exhaustive search\n",
        "\n",
        "3. product quantization\n",
        "\n",
        "4.  trees and graphs\n",
        "\n",
        "5.  hnsw"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3aT8bzJp4Mh",
        "outputId": "b8d415c0-feb2-4a23-9b5e-580b252a6ae6"
      },
      "source": [
        "!pip install datasketch\n",
        "!pip install watermark\n",
        "!pip install mlxtend \n",
        "!pip install faiss\n",
        "# Using rpforest\n",
        "!pip install rpforest\n",
        "!pip install faiss-cpu"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasketch in /usr/local/lib/python3.7/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from datasketch) (1.19.5)\n",
            "Requirement already satisfied: watermark in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from watermark) (5.5.0)\n",
            "Requirement already satisfied: importlib-metadata<3.0 in /usr/local/lib/python3.7/dist-packages (from watermark) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<3.0->watermark) (3.6.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (5.1.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->watermark) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->watermark) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->watermark) (0.7.0)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.4.0)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.1.0)\n",
            "Requirement already satisfied: faiss in /usr/local/lib/python3.7/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.19.5)\n",
            "Requirement already satisfied: rpforest in /usr/local/lib/python3.7/dist-packages (1.6)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from rpforest) (1.19.5)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.7/dist-packages (1.7.1.post2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GOJc7uPgt1l"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lStdDoVD_9N_"
      },
      "source": [
        "# 1. LSH\n",
        "\n",
        "**LSH** stands for Locality-sensitive hashing. This technique hashes similar input items into the same \"bucket\" with high probability. It is used to find the nearest neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV44lYd8TucY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fa4cd7-1ef8-4b47-8c41-8a5af925835f"
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "%load_ext watermark\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import time\n",
        "from datasketch import MinHash, MinHashLSHForest\n",
        "\n",
        "%watermark -a 'Manjiri Kadam' -d -t -v -p numpy,pandas,sklearn,matplotlib"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The watermark extension is already loaded. To reload it, use:\n",
            "  %reload_ext watermark\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Author: Manjiri Kadam\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.7.12\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "numpy     : 1.19.5\n",
            "pandas    : 1.1.5\n",
            "sklearn   : 0.0\n",
            "matplotlib: 3.2.2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MWH6mMNg019",
        "outputId": "d9a88964-2f82-4776-db2a-cc3b29149e05"
      },
      "source": [
        "# Mounting the google drive\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BIDXszbniVWW",
        "outputId": "3c69c932-493a-472c-bb9c-e0a13e052087"
      },
      "source": [
        "#Read the dataset as a dataframe:\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/dataset/fox_news.csv')\n",
        "#Displaying the data:\n",
        "df.head(5)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Rep. Brady: Inflation as big a concern to Amer...</td>\n",
              "      <td>https://video.foxnews.com/v/6283107807001/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\\nOlympic committee says it spoke with missing...</td>\n",
              "      <td>https://www.foxnews.com/world/peng-shuai-olymp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Rep. Brady: Inflation as big a concern to Amer...</td>\n",
              "      <td>https://video.foxnews.com/v/6283107807001/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The Blue is back with a brand new, action-pack...</td>\n",
              "      <td>https://nation.foxnews.com/watch/5852616534e7d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\\nKyle Rittenhouse to appear on 'Tucker Carlso...</td>\n",
              "      <td>https://www.foxnews.com/media/kyle-rittenhouse...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                               Link\n",
              "0           0  ...         https://video.foxnews.com/v/6283107807001/\n",
              "1           1  ...  https://www.foxnews.com/world/peng-shuai-olymp...\n",
              "2           2  ...         https://video.foxnews.com/v/6283107807001/\n",
              "3           3  ...  https://nation.foxnews.com/watch/5852616534e7d...\n",
              "4           4  ...  https://www.foxnews.com/media/kyle-rittenhouse...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "zBFs_KcCjjKn",
        "outputId": "2b11ec6e-78c5-4efe-e499-2cc84c1ef373"
      },
      "source": [
        "df.sample(2)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>113</td>\n",
              "      <td>Khloe Kardashian slammed for Kyle Rittenhouse ...</td>\n",
              "      <td>https://www.foxnews.com/entertainment/khloe-ka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>92</td>\n",
              "      <td>Media malpractice on Kyle Rittenhouse</td>\n",
              "      <td>https://video.foxnews.com/v/6283078170001/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...                                               Link\n",
              "113         113  ...  https://www.foxnews.com/entertainment/khloe-ka...\n",
              "92           92  ...         https://video.foxnews.com/v/6283078170001/\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlSQSfDbmLM_"
      },
      "source": [
        "def preprocess(text):\n",
        "    text = re.sub(r'[^\\w\\s]','',text)\n",
        "    tokens = text.lower()\n",
        "    tokens = tokens.split()\n",
        "    return tokens"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpPOPMIDp-kO",
        "outputId": "319d83f6-a39d-4092-e1ec-23452498f042"
      },
      "source": [
        "text = 'The devil went down to Georgia'\n",
        "print('The shingles (tokens) are:', preprocess(text))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shingles (tokens) are: ['the', 'devil', 'went', 'down', 'to', 'georgia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dfcKb7eqBGr"
      },
      "source": [
        "df['shingles'] = df['Statement'].apply(preprocess)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "fnzK2wHVrCu7",
        "outputId": "326608f3-5118-481f-e82b-fbd9d0ed3f27"
      },
      "source": [
        "df.sample(2)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Link</th>\n",
              "      <th>shingles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>Joy Reid says Kyle Rittenhouse acquittal trace...</td>\n",
              "      <td>https://www.foxnews.com/media/msnbc-joy-reid-k...</td>\n",
              "      <td>[joy, reid, says, kyle, rittenhouse, acquittal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>57</td>\n",
              "      <td>Political cartoon of the day: Taking notes</td>\n",
              "      <td>https://www.foxnews.com/politics/cartoons-slid...</td>\n",
              "      <td>[political, cartoon, of, the, day, taking, notes]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  ...                                           shingles\n",
              "19          19  ...  [joy, reid, says, kyle, rittenhouse, acquittal...\n",
              "57          57  ...  [political, cartoon, of, the, day, taking, notes]\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxjdtkrArEjt"
      },
      "source": [
        "#Number of Permutations\n",
        "permutations = 128\n",
        "\n",
        "#Number of Recommendations to return\n",
        "num_recommendations = 1"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3vO-YPQrM38"
      },
      "source": [
        "def get_forest(data):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    minhash = []\n",
        "    \n",
        "    for text in df['Statement']:\n",
        "        tokens = preprocess(text)\n",
        "        m = MinHash(num_perm=128)\n",
        "        for s in tokens:\n",
        "            m.update(s.encode('utf8'))\n",
        "        minhash.append(m)\n",
        "        \n",
        "    forest = MinHashLSHForest(num_perm=128)\n",
        "    \n",
        "    for i,m in enumerate(minhash):\n",
        "        forest.add(i,m)\n",
        "        \n",
        "    forest.index()\n",
        "    \n",
        "    print('It took %s seconds to build forest.' %(time.time()-start_time))\n",
        "    \n",
        "    return forest"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxsBjkhArWH6"
      },
      "source": [
        "def predict(text, df, perms, num_results, forest):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    tokens = preprocess(text)\n",
        "    m = MinHash(num_perm=perms)\n",
        "    for s in tokens:\n",
        "        m.update(s.encode('utf8'))\n",
        "        \n",
        "    idx_array = np.array(forest.query(m, num_results))\n",
        "    if len(idx_array) == 0:\n",
        "        return None # if your query is empty, return none\n",
        "    \n",
        "    result = df.iloc[idx_array]#['title']\n",
        "    \n",
        "    print('It took %s seconds to query forest.' %(time.time()-start_time))\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKygmkXTrYP6",
        "outputId": "ca5196e6-0d3e-47ff-ccea-f2b7af0f407b"
      },
      "source": [
        "df['forest'] = df['Statement'].apply(get_forest)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 0.2246265411376953 seconds to build forest.\n",
            "It took 0.2023475170135498 seconds to build forest.\n",
            "It took 0.20916175842285156 seconds to build forest.\n",
            "It took 0.20604562759399414 seconds to build forest.\n",
            "It took 0.20813918113708496 seconds to build forest.\n",
            "It took 0.20472979545593262 seconds to build forest.\n",
            "It took 0.21049904823303223 seconds to build forest.\n",
            "It took 0.19683337211608887 seconds to build forest.\n",
            "It took 0.1992795467376709 seconds to build forest.\n",
            "It took 0.20030665397644043 seconds to build forest.\n",
            "It took 0.2006828784942627 seconds to build forest.\n",
            "It took 0.20059919357299805 seconds to build forest.\n",
            "It took 0.19954609870910645 seconds to build forest.\n",
            "It took 0.20637798309326172 seconds to build forest.\n",
            "It took 0.18982791900634766 seconds to build forest.\n",
            "It took 0.20895624160766602 seconds to build forest.\n",
            "It took 0.19698119163513184 seconds to build forest.\n",
            "It took 0.1928539276123047 seconds to build forest.\n",
            "It took 0.1908888816833496 seconds to build forest.\n",
            "It took 0.20530247688293457 seconds to build forest.\n",
            "It took 0.23001980781555176 seconds to build forest.\n",
            "It took 0.19559741020202637 seconds to build forest.\n",
            "It took 0.1865549087524414 seconds to build forest.\n",
            "It took 0.19837713241577148 seconds to build forest.\n",
            "It took 0.2030332088470459 seconds to build forest.\n",
            "It took 0.21196675300598145 seconds to build forest.\n",
            "It took 0.19612407684326172 seconds to build forest.\n",
            "It took 0.19827818870544434 seconds to build forest.\n",
            "It took 0.21326661109924316 seconds to build forest.\n",
            "It took 0.29454469680786133 seconds to build forest.\n",
            "It took 0.2337026596069336 seconds to build forest.\n",
            "It took 0.2093210220336914 seconds to build forest.\n",
            "It took 0.19511866569519043 seconds to build forest.\n",
            "It took 0.19177532196044922 seconds to build forest.\n",
            "It took 0.21439409255981445 seconds to build forest.\n",
            "It took 0.21186518669128418 seconds to build forest.\n",
            "It took 0.18897032737731934 seconds to build forest.\n",
            "It took 0.19834637641906738 seconds to build forest.\n",
            "It took 0.2003459930419922 seconds to build forest.\n",
            "It took 0.21355390548706055 seconds to build forest.\n",
            "It took 0.2088329792022705 seconds to build forest.\n",
            "It took 0.20758748054504395 seconds to build forest.\n",
            "It took 0.18701529502868652 seconds to build forest.\n",
            "It took 0.2021331787109375 seconds to build forest.\n",
            "It took 0.20478558540344238 seconds to build forest.\n",
            "It took 0.19974112510681152 seconds to build forest.\n",
            "It took 0.19883942604064941 seconds to build forest.\n",
            "It took 0.20164823532104492 seconds to build forest.\n",
            "It took 0.2230515480041504 seconds to build forest.\n",
            "It took 0.20495247840881348 seconds to build forest.\n",
            "It took 0.20939350128173828 seconds to build forest.\n",
            "It took 0.2045276165008545 seconds to build forest.\n",
            "It took 0.20847654342651367 seconds to build forest.\n",
            "It took 0.1973421573638916 seconds to build forest.\n",
            "It took 0.2234487533569336 seconds to build forest.\n",
            "It took 0.19184136390686035 seconds to build forest.\n",
            "It took 0.2011704444885254 seconds to build forest.\n",
            "It took 0.19907736778259277 seconds to build forest.\n",
            "It took 0.20642924308776855 seconds to build forest.\n",
            "It took 0.2028346061706543 seconds to build forest.\n",
            "It took 0.21671605110168457 seconds to build forest.\n",
            "It took 0.19054770469665527 seconds to build forest.\n",
            "It took 0.19243955612182617 seconds to build forest.\n",
            "It took 0.21533703804016113 seconds to build forest.\n",
            "It took 0.2267777919769287 seconds to build forest.\n",
            "It took 0.21015262603759766 seconds to build forest.\n",
            "It took 0.1959083080291748 seconds to build forest.\n",
            "It took 0.20501422882080078 seconds to build forest.\n",
            "It took 0.19719529151916504 seconds to build forest.\n",
            "It took 0.21854114532470703 seconds to build forest.\n",
            "It took 0.19261527061462402 seconds to build forest.\n",
            "It took 0.20319890975952148 seconds to build forest.\n",
            "It took 0.1927182674407959 seconds to build forest.\n",
            "It took 0.2200758457183838 seconds to build forest.\n",
            "It took 0.20739150047302246 seconds to build forest.\n",
            "It took 0.19579792022705078 seconds to build forest.\n",
            "It took 0.1957683563232422 seconds to build forest.\n",
            "It took 0.20768165588378906 seconds to build forest.\n",
            "It took 0.19974160194396973 seconds to build forest.\n",
            "It took 0.2027266025543213 seconds to build forest.\n",
            "It took 0.19581151008605957 seconds to build forest.\n",
            "It took 0.19330883026123047 seconds to build forest.\n",
            "It took 0.2068188190460205 seconds to build forest.\n",
            "It took 0.20175480842590332 seconds to build forest.\n",
            "It took 0.1818680763244629 seconds to build forest.\n",
            "It took 0.21234989166259766 seconds to build forest.\n",
            "It took 0.20322847366333008 seconds to build forest.\n",
            "It took 0.2101917266845703 seconds to build forest.\n",
            "It took 0.20485901832580566 seconds to build forest.\n",
            "It took 0.20877766609191895 seconds to build forest.\n",
            "It took 0.20215654373168945 seconds to build forest.\n",
            "It took 0.20154953002929688 seconds to build forest.\n",
            "It took 0.19746828079223633 seconds to build forest.\n",
            "It took 0.20639443397521973 seconds to build forest.\n",
            "It took 0.22172188758850098 seconds to build forest.\n",
            "It took 0.2263638973236084 seconds to build forest.\n",
            "It took 0.23026180267333984 seconds to build forest.\n",
            "It took 0.20892643928527832 seconds to build forest.\n",
            "It took 0.1988205909729004 seconds to build forest.\n",
            "It took 0.22921204566955566 seconds to build forest.\n",
            "It took 0.19965434074401855 seconds to build forest.\n",
            "It took 0.23183393478393555 seconds to build forest.\n",
            "It took 0.20698881149291992 seconds to build forest.\n",
            "It took 0.19925832748413086 seconds to build forest.\n",
            "It took 0.20511078834533691 seconds to build forest.\n",
            "It took 0.19186830520629883 seconds to build forest.\n",
            "It took 0.2007615566253662 seconds to build forest.\n",
            "It took 0.2193136215209961 seconds to build forest.\n",
            "It took 0.19379448890686035 seconds to build forest.\n",
            "It took 0.20655393600463867 seconds to build forest.\n",
            "It took 0.19818711280822754 seconds to build forest.\n",
            "It took 0.2242879867553711 seconds to build forest.\n",
            "It took 0.21976041793823242 seconds to build forest.\n",
            "It took 0.1973717212677002 seconds to build forest.\n",
            "It took 0.21197843551635742 seconds to build forest.\n",
            "It took 0.1855149269104004 seconds to build forest.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "h4KwvGkWrfFB",
        "outputId": "abe14ed3-1138-40c4-f6f7-cbc033a67b09"
      },
      "source": [
        "df.sample(2)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Link</th>\n",
              "      <th>shingles</th>\n",
              "      <th>forest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>102</td>\n",
              "      <td>Georgia suspect in cop's stabbing is now linke...</td>\n",
              "      <td>https://www.foxnews.com/us/georgia-suspect-in-...</td>\n",
              "      <td>[georgia, suspect, in, cops, stabbing, is, now...</td>\n",
              "      <td>&lt;datasketch.lshforest.MinHashLSHForest object ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>Chris Christie on importance of Republicans ge...</td>\n",
              "      <td>https://video.foxnews.com/v/6283074523001/</td>\n",
              "      <td>[chris, christie, on, importance, of, republic...</td>\n",
              "      <td>&lt;datasketch.lshforest.MinHashLSHForest object ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...                                             forest\n",
              "102         102  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
              "96           96  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lG01yj8wKpA",
        "outputId": "8da0292b-fc58-44ef-98dc-4d5f68e58909"
      },
      "source": [
        "forest = get_forest(df)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 0.19727063179016113 seconds to build forest.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i31J-Swuc1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "bfd9d9a7-9f99-4770-c740-5bd36d884dbc"
      },
      "source": [
        "num_recommendations = 5\n",
        "title = 'Using a neural net to instantiate a deformable model'\n",
        "result = predict(title, df, permutations, num_recommendations, forest)\n",
        "print('\\n Top Recommendation(s) is(are) \\n', result)\n",
        "df.head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 0.002725362777709961 seconds to query forest.\n",
            "\n",
            " Top Recommendation(s) is(are) \n",
            "     Unnamed: 0  ...                                             forest\n",
            "4            4  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
            "72          72  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
            "14          14  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
            "19          19  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
            "62          62  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Link</th>\n",
              "      <th>shingles</th>\n",
              "      <th>forest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Rep. Brady: Inflation as big a concern to Amer...</td>\n",
              "      <td>https://video.foxnews.com/v/6283107807001/</td>\n",
              "      <td>[rep, brady, inflation, as, big, a, concern, t...</td>\n",
              "      <td>&lt;datasketch.lshforest.MinHashLSHForest object ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\\nOlympic committee says it spoke with missing...</td>\n",
              "      <td>https://www.foxnews.com/world/peng-shuai-olymp...</td>\n",
              "      <td>[olympic, committee, says, it, spoke, with, mi...</td>\n",
              "      <td>&lt;datasketch.lshforest.MinHashLSHForest object ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Rep. Brady: Inflation as big a concern to Amer...</td>\n",
              "      <td>https://video.foxnews.com/v/6283107807001/</td>\n",
              "      <td>[rep, brady, inflation, as, big, a, concern, t...</td>\n",
              "      <td>&lt;datasketch.lshforest.MinHashLSHForest object ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The Blue is back with a brand new, action-pack...</td>\n",
              "      <td>https://nation.foxnews.com/watch/5852616534e7d...</td>\n",
              "      <td>[the, blue, is, back, with, a, brand, new, act...</td>\n",
              "      <td>&lt;datasketch.lshforest.MinHashLSHForest object ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\\nKyle Rittenhouse to appear on 'Tucker Carlso...</td>\n",
              "      <td>https://www.foxnews.com/media/kyle-rittenhouse...</td>\n",
              "      <td>[kyle, rittenhouse, to, appear, on, tucker, ca...</td>\n",
              "      <td>&lt;datasketch.lshforest.MinHashLSHForest object ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                             forest\n",
              "0           0  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
              "1           1  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
              "2           2  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
              "3           3  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
              "4           4  ...  <datasketch.lshforest.MinHashLSHForest object ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34PTzO-H42cc"
      },
      "source": [
        "#  B) exhaustive search ➿\n",
        "\n",
        "Exhaustive search is brute force method of finding Aproximate Nearest Neighbour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpPVWNPI46T0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4d803a17-462f-4cb4-e053-a9a0c6ccdffa"
      },
      "source": [
        "# Exhaustive search is brute force method.\n",
        "# Using Housing Boston dataset\n",
        "\n",
        "column_names = ['Crime', 'ZN', 'INDUS', 'CHAS', 'NOXconc', 'Room', 'AGE', 'DIS', 'RAD', 'Tax', 'PTRatio', 'B', 'LSTAT', 'MedValue']\n",
        "df2= pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)\n",
        "df2.head(5)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Crime</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOXconc</th>\n",
              "      <th>Room</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>Tax</th>\n",
              "      <th>PTRatio</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MedValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Crime    ZN  INDUS  CHAS  NOXconc  ...    Tax  PTRatio       B  LSTAT  MedValue\n",
              "0  0.00632  18.0   2.31     0    0.538  ...  296.0     15.3  396.90   4.98      24.0\n",
              "1  0.02731   0.0   7.07     0    0.469  ...  242.0     17.8  396.90   9.14      21.6\n",
              "2  0.02729   0.0   7.07     0    0.469  ...  242.0     17.8  392.83   4.03      34.7\n",
              "3  0.03237   0.0   2.18     0    0.458  ...  222.0     18.7  394.63   2.94      33.4\n",
              "4  0.06905   0.0   2.18     0    0.458  ...  222.0     18.7  396.90   5.33      36.2\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1uWrqgwgMH5"
      },
      "source": [
        "# Including the Sklearn library for exhaustive search\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# import sklearn.externals as extjoblib\n",
        "import joblib\n",
        "import sys\n",
        "sys.modules['sklearn.externals.joblib'] = joblib\n",
        "from sklearn.datasets import load_boston\n",
        "\n",
        "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6CJwQTvfuZ4",
        "outputId": "413cce43-1a5c-482e-c257-71380bda28c4"
      },
      "source": [
        "\n",
        "boston = load_boston()\n",
        "X, y = boston.data, boston.target"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQzTsKNXgH1F",
        "outputId": "d1beb273-b188-4151-a000-33fee7ab571a"
      },
      "source": [
        "lr = LinearRegression()\n",
        "\n",
        "efs = EFS(lr, \n",
        "          min_features=10,\n",
        "          max_features=12,\n",
        "          scoring='neg_mean_squared_error',\n",
        "          cv=10)\n",
        "\n",
        "efs.fit(X, y)\n",
        "\n",
        "print('Best MSE score: %.2f' % efs.best_score_ * (-1))\n",
        "print('Best subset:', efs.best_idx_)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Features: 377/377"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best subset: (0, 1, 4, 6, 7, 8, 9, 10, 11, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Qs5Bu5gkEX"
      },
      "source": [
        "# http://rasbt.github.io/mlxtend/user_guide/feature_selection/ExhaustiveFeatureSelector/#exhaustive-feature-selector"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1AhYbFvh4x_"
      },
      "source": [
        "# c) product quantization ♒\n",
        "It is a type of ANN . In this method it decompose the space into a Cartesian product of low dimensional subspace and then quantize each subspace separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOEv_WuYh9Yp"
      },
      "source": [
        "# Implementing Product Quantization using FAISS\n",
        "# Importing required libraries\n",
        "import faiss"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MhIRiT3ljki"
      },
      "source": [
        "dimension = 128    # dimensions of each vector                         \n",
        "n = 256    # number of vectors                   \n",
        "np.random.seed(1)             \n",
        "db_vectors = np.random.random((n, dimension)).astype('float32')"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0ae3qTOmzMI"
      },
      "source": [
        "m=8\n",
        "nlist = 5  # number of clusters\n",
        "quantizer = faiss.IndexFlatL2(dimension)  # coarse quantizer\n",
        " \n",
        "#define the inverted index \n",
        "index = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, 8)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddkPC7YWm6EE"
      },
      "source": [
        "# train index on the database vectors:\n",
        "index.train(db_vectors)\n",
        "index.add(db_vectors)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFCWfAqJnD4_",
        "outputId": "7015bbda-1d6b-44c2-a83f-7596f8040ab0"
      },
      "source": [
        "nprobe = 2  # find 2 most similar clusters\n",
        "n_query = 10\n",
        "k = 3  # return 3 nearest neighbours,\n",
        "np.random.seed(0)   \n",
        "query_vectors = np.random.random((n_query, dimension)).astype('float32')\n",
        "distances, indices = index.search(query_vectors, k)\n",
        "print(distances)\n",
        "print(indices)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15.95562  15.998074 16.059832]\n",
            " [16.276657 18.102848 18.522284]\n",
            " [15.520997 16.500257 16.77318 ]\n",
            " [18.64824  18.720179 18.868248]\n",
            " [17.3755   18.019579 18.28939 ]\n",
            " [16.375307 17.643938 17.803608]\n",
            " [14.23982  15.031904 15.587464]\n",
            " [16.380919 16.686506 17.270594]\n",
            " [16.17979  18.766174 18.855637]\n",
            " [17.293684 17.385288 17.451862]]\n",
            "[[ 19   4 245]\n",
            " [  6 110  51]\n",
            " [148 149 216]\n",
            " [117  29  27]\n",
            " [ 82 196  16]\n",
            " [ 51 141 127]\n",
            " [ 16 196  60]\n",
            " [ 12 216  46]\n",
            " [142  59 248]\n",
            " [245  46  19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCXj7oyi55U9"
      },
      "source": [
        ""
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksUvS1Q16O20"
      },
      "source": [
        "# d) trees and graphs#\n",
        "For the assignment, used annoy library by Spotify. It is the fastest library for nearest neighbour search. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIFik73p9Kci",
        "outputId": "f2616465-0ef5-45f7-d6e2-97fa23a94061"
      },
      "source": [
        "!pip install annoy"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: annoy in /usr/local/lib/python3.7/dist-packages (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J12qsDiIH8yu"
      },
      "source": [
        "X = df['Statement']"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Jh4GeeIGx7"
      },
      "source": [
        "# from rpforest import RPForest\n",
        "\n",
        "# model = RPForest(leaf_size=50, no_trees=10)\n",
        "# model.fit(X)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4noDV3GvIKmb"
      },
      "source": [
        "import pickle\n",
        "import annoy"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeJ4xyNA9INd",
        "outputId": "02cad671-dec5-42a3-a64a-1b87dacf0cd2"
      },
      "source": [
        "def load_data():\n",
        "    with open('/content/gdrive/MyDrive/Data_Mining/movies.pickle', 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "data = load_data()\n",
        "data\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
              " 'vector': array([[-0.01780608, -0.14265831,  0.10308606, ...,  0.09659795,\n",
              "         -0.17529577, -0.03061521],\n",
              "        [-0.03357764,  0.16418771,  0.21801303, ...,  0.16502103,\n",
              "         -0.09166156,  0.05047869],\n",
              "        [-0.2761452 , -0.01991325, -0.04969981, ...,  0.0258275 ,\n",
              "         -0.08328608, -0.0152858 ],\n",
              "        ...,\n",
              "        [ 0.05142734, -0.01683608, -0.20441587, ...,  0.00045828,\n",
              "          0.14679626,  0.2462584 ],\n",
              "        [ 0.04491899, -0.02819411, -0.09472758, ..., -0.02152078,\n",
              "          0.16223577,  0.19897607],\n",
              "        [ 0.02531924,  0.03099714,  0.06437534, ..., -0.07260127,\n",
              "          0.0467432 ,  0.07893164]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JS7AyY99k9f"
      },
      "source": [
        "class AnnoyIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def build(self, number_of_trees=5):\n",
        "        self.index = annoy.AnnoyIndex(self.dimention)\n",
        "        for i, vec in enumerate(self.vectors):\n",
        "            self.index.add_item(i, vec.tolist())\n",
        "        self.index.build(number_of_trees)\n",
        "        \n",
        "    def query(self, vector, k=10):\n",
        "        indices = self.index.get_nns_by_vector(vector.tolist(), k)\n",
        "        return [self.labels[i] for i in indices]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4c6TzYD9tRl",
        "outputId": "c57327d7-d2c5-496d-952f-4ad304f9c9f7"
      },
      "source": [
        "index = AnnoyIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: The default argument for metric will be removed in future version of Annoy. Please pass metric='angular' explicitly.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QJRoquY9vx0",
        "outputId": "c7644229-225d-4d94-b5fd-e5c888f267d9"
      },
      "source": [
        "movie_vector, movie_name = data['vector'][90], data['name'][90]\n",
        "simlar_movies_names = '\\n* '.join(index.query(movie_vector))\n",
        "print(f\"The most similar movies to {movie_name} are:\\n* {simlar_movies_names}\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar movies to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Aladdin (1992)\n",
            "* Blade Runner (1982)\n",
            "* Aliens (1986)\n",
            "* Pink Floyd - The Wall (1982)\n",
            "* Brazil (1985)\n",
            "* Wrong Trousers, The (1993)\n",
            "* Alien (1979)\n",
            "* Return of the Jedi (1983)\n",
            "* E.T. the Extra-Terrestrial (1982)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tQCfWib90nI"
      },
      "source": [
        "# e) hnsw"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QJVo8yi_UvD",
        "outputId": "b2b33493-f970-4699-f873-dfae1cccca6c"
      },
      "source": [
        "!pip install nmslib"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nmslib in /usr/local/lib/python3.7/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from nmslib) (1.19.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib) (5.4.8)\n",
            "Requirement already satisfied: pybind11<2.6.2 in /usr/local/lib/python3.7/dist-packages (from nmslib) (2.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bhpRZDp984L"
      },
      "source": [
        "import nmslib"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA9uOatY_Tp3"
      },
      "source": [
        "class NMSLIBIndex():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "    def build(self):\n",
        "        self.index = nmslib.init(method='hnsw', space='cosinesimil')\n",
        "        self.index.addDataPointBatch(self.vectors)\n",
        "        self.index.createIndex({'post': 2})\n",
        "        \n",
        "    def query(self, vector, k=10):\n",
        "        indices = self.index.knnQuery(vector, k=k)\n",
        "        return [self.labels[i] for i in indices[0]]"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZszFVvH2_mvN"
      },
      "source": [
        "index = NMSLIBIndex(data[\"vector\"], data[\"name\"])\n",
        "index.build()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNJ4C6UV_pKo",
        "outputId": "1a49bd77-bb91-4c0a-e6f2-b25af2726799"
      },
      "source": [
        "movie_vector, movie_name = data['vector'][90], data['name'][90]\n",
        "simlar_movies_names = '\\n* '.join(index.query(movie_vector))\n",
        "print(f\"The most similar movies to {movie_name} are:\\n* {simlar_movies_names}\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar movies to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Beauty and the Beast (1991)\n",
            "* Fantasia (1940)\n",
            "* Heavy Metal (1981)\n",
            "* Aladdin (1992)\n",
            "* Snow White and the Seven Dwarfs (1937)\n",
            "* Batman (1989)\n",
            "* James and the Giant Peach (1996)\n",
            "* Blade Runner (1982)\n",
            "* Aliens (1986)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBBNHgzM_srM"
      },
      "source": [
        ""
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbHDQhUaBfvE"
      },
      "source": [
        "### References▶\n",
        "1.  https://towardsdatascience.com/locality-sensitive-hashing-in-nlp-1fb3d4a7ba9f\n",
        "2.  https://www.learndatasci.com/tutorials/building-recommendation-engine-locality-sensitive-hashing-lsh-python/\n",
        "3. http://ethen8181.github.io/machine-learning/recsys/content_based/lsh_text.html\n",
        "4. https://github.com/eyaltrabelsi/my-notebooks/tree/master/Lectures/search_in_practice-approximate_nearest_neighbors"
      ]
    }
  ]
}